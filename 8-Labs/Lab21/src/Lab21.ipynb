{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download** (right-click, save target as ...) this page as a jupyterlab notebook [Lab21](http://54.243.252.9/engr-1330-webroot/8-Labs/Lab21/Lab21.ipynb)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>Laboratory 21: Probability Estimation Modeling </font>\n",
    "\n",
    "LAST NAME, FIRST NAME\n",
    "\n",
    "R00000000\n",
    "\n",
    "ENGR 1330 Laboratory 21 - In-Lab\n",
    "\n",
    "___\n",
    "\n",
    "**Important Hint** You will find it useful to have the Lab 21 HTML notebook available to cut and paste code -- the lab HTML is presented as complete, whereas the lab IPYNB is not completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Terminology:\n",
    "__Population:__ In statistics, a population is the entire pool from which a statistical sample is drawn. A population may refer to an entire group of people, objects, events, hospital visits, or measurements. <br>\n",
    "__Sample:__ In statistics and quantitative research methodology, a sample is a set of individuals or objects collected or selected from a statistical population by a defined procedure. The elements of a sample are known as sample points, sampling units or observations.<br>\n",
    "__Distribution (Data Model):__ A data distribution is a function or a listing which shows all the possible values (or intervals) of the data. It also (and this is important) tells you how often each value occurs. <br>\n",
    "\n",
    "__*From https://www.investopedia.com/terms*__<br>\n",
    "__*https://www.statisticshowto.com/data-distribution/*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Important Steps:\n",
    "1. __Get descriptive statistics- mean, variance, std. dev.__\n",
    "2. __Use plotting position formulas (e.g., weibull, gringorten, cunnane) and plot the SAMPLES (data you already have)__\n",
    "3. __Use different data models (e.g., normal, log-normal, Gumbell) and find the one that better FITs your samples- Visual or Numerical__\n",
    "4. __Use the data model that provides the best fit to infer about the POPULATION__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the magnitude of the annual peak flow at Spring Ck near Spring, TX.\n",
    "\n",
    "The file `08068500.pkf` is an actual WATSTORE formatted file for a USGS gage at Spring Creek, Texas. The first few lines of the file look like:\n",
    "\n",
    "    Z08068500                       USGS \n",
    "    H08068500       3006370952610004848339SW12040102409    409     72.6             \n",
    "    N08068500       Spring Ck nr Spring, TX\n",
    "    Y08068500       \n",
    "    308068500       19290530  483007              34.30        1879          \n",
    "    308068500       19390603    838               13.75                    \n",
    "    308068500       19400612   3420               21.42                    \n",
    "    308068500       19401125  42700               33.60                    \n",
    "    308068500       19420409  14200               27.78                    \n",
    "    308068500       19430730   8000               25.09                    \n",
    "    308068500       19440319   5260               23.15                    \n",
    "    308068500       19450830  31100               32.79                    \n",
    "    308068500       19460521  12200               27.97                 \n",
    "    \n",
    "The first column are some agency codes that identify the station , the second column after the fourth row is a date in YYYYMMDD format, the third column is a discharge in CFS, the fourth and fifth column are not relevant for this laboratory exercise.  The file was downloadef from\n",
    "\n",
    "https://nwis.waterdata.usgs.gov/tx/nwis/peak?site_no=08068500&agency_cd=USGS&format=hn2\n",
    "\n",
    "In the original file there are a couple of codes that are manually removed:\n",
    "\n",
    "- 19290530  483007;  the trailing 7 is a code identifying a break in the series (non-sequential)\n",
    "- 20170828  784009; the trailing 9 identifies the historical peak\n",
    "\n",
    "The laboratory task is to fit the data models to this data, decide the best model from visual perspective, and report from that data model the magnitudes of peak flow associated with the probebilitiess below (i.e. populate the table)\n",
    "\n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "The first step is to read the file, skipping the first part, then build a dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file from http://54.243.252.9/engr-1330-webroot/8-Labs/Lab21/08068500.pkf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file\n",
    "amatrix = [] # null list to store matrix reads\n",
    "rowNumA = 0\n",
    "matrix1=[]\n",
    "col0=[]\n",
    "col1=[]\n",
    "col2=[]\n",
    "with open('08068500.pkf','r') as afile:\n",
    "    lines_after_4 = afile.readlines()[4:]\n",
    "afile.close() # Disconnect the file\n",
    "howmanyrows = len(lines_after_4)\n",
    "for i in range(howmanyrows):\n",
    "    matrix1.append(lines_after_4[i].strip().split())\n",
    "for i in range(howmanyrows):\n",
    "    col0.append(int(matrix1[i][0]))\n",
    "    col1.append(matrix1[i][1])\n",
    "    col2.append(int(matrix1[i][2])) #We need to conver it to integers \n",
    "# col2 is date, col3 is peak flow\n",
    "#now build a datafranem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "df = pandas.DataFrame(col0)\n",
    "df['date']= col1\n",
    "df['flow']= col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>date</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308068500</td>\n",
       "      <td>19290530</td>\n",
       "      <td>48300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308068500</td>\n",
       "      <td>19390603</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308068500</td>\n",
       "      <td>19400612</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308068500</td>\n",
       "      <td>19401125</td>\n",
       "      <td>42700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>308068500</td>\n",
       "      <td>19420409</td>\n",
       "      <td>14200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      date   flow\n",
       "0  308068500  19290530  48300\n",
       "1  308068500  19390603    838\n",
       "2  308068500  19400612   3420\n",
       "3  308068500  19401125  42700\n",
       "4  308068500  19420409  14200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore if you can plot the dataframe as a plot of peaks versus date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on you can proceede using the lecture notebook as a go-by, although you should use functions as much as practical to keep your work concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weibull Plotting Position Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Quantile Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Data to Normal Data Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution Data Model\n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Normal Quantile Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Data to Normal Data Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Normal Distribution Data Model\n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gumbell EV1 Quantile Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Data to Gumbell EV1 Data Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gumbell Double Exponential (EV1) Distribution Data Model\n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma (Pearson Type III) Quantile Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Data to Pearson (Gamma) III Data Model \n",
    "# This is new, in lecture the fit was to log-Pearson, same procedure, but not log transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson III Distribution Data Model \n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Data to Log-Pearson (Log-Gamma) III Data Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Pearson III Distribution Data Model\n",
    "|Exceedence Probability|Flow Value|Remarks|\n",
    "|:---|:---|:---|\n",
    "|25% |????| 75% chance of greater value|           \n",
    "|50% |????| 50% chance of greater value|            \n",
    "|75% |????| 25% chance of greater value|            \n",
    "|90% |????| 10% chance of greater value|\n",
    "|99% |????| 1% chance of greater value (in flood statistics, this is the 1 in 100-yr chance event)|\n",
    "|99.8%|????| 0.002% chance of greater value (in flood statistics, this is the 1 in 500-yr chance event)|\n",
    "|99.9%|????| 0.001% chance of greater value (in flood statistics, this is the 1 in 1000-yr chance event)|\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of \"Best\" Data Model based on Graphical Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your interpretation here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
